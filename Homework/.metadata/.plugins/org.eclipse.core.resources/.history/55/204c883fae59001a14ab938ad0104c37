package t3;

import java.util.*;

/**
 * Artificial Intelligence responsible for playing the game of T3!
 * Implements the alpha-beta-pruning mini-max search algorithm
 */
public class T3Player {
    
    /**
     * Workhorse of an AI T3Player's choice mechanics that, given a game state,
     * makes the optimal choice from that state as defined by the mechanics of
     * the game of Tic-Tac-Total.
     * Note: In the event that multiple moves have equivalently maximal minimax
     * scores, ties are broken by move col, then row, then move number in ascending
     * order (see spec and unit tests for more info). The agent will also always
     * take an immediately winning move over a delayed one (e.g., 2 moves in the future).
     * @param state The state from which the T3Player is making a move decision.
     * @return The T3Player's optimal action.
     */
    public T3Action choose (T3State state) {
    	return alphabeta(new Tuple(), state, Integer.MIN_VALUE, Integer.MAX_VALUE, true).bestAction;
    }
    
    
    private Tuple alphabeta(Tuple data, T3State state, int alpha, int beta, boolean maximizingPlayer) {
    	Tuple child = null;
    	int v = 0;
    	Map<T3Action, T3State> children = state.getTransitions();
    	if(state.isWin()) {
    		data.utilityCost = !maximizingPlayer?2: 0;
    	} else if (state.isTie()) {
    		data.utilityCost = 1;
    	} else if(maximizingPlayer) {
    		v = Integer.MIN_VALUE;
    		for(T3Action action : children.keySet()) {
    			if(children.get(action).isWin()) {
    				data.utilityCost= 2+1;
    				data.bestAction = action;
    				return data;
    			}
				child = alphabeta(new Tuple(), children.get(action), alpha, beta, false);
				v = Math.max(v, child.utilityCost);
				if (alpha < v) {
					alpha = v;
					data.bestAction = action;
					data.utilityCost = child.utilityCost;
				}
				if (beta <= alpha) {
					break;
        			}
    		}
    	} else { 
    		v = Integer.MAX_VALUE;
    		for(T3Action action : children.keySet()) {
    			child = alphabeta(new Tuple(), children.get(action), alpha, beta, true);
    			v= Math.min(v, child.utilityCost);
    			beta = Math.min(beta, v);
    			if(beta <= alpha) {
    				break;
    			}
    		}
    	}
    	return data;
    
    // TODO: Implement your alpha-beta pruning recursive helper here!
    }
    private class Tuple {
    	int utilityCost;
    	T3Action bestAction;
    	
    	Tuple(){
    		this.bestAction = null;
    		utilityCost = -1;
    	}
    	
    }
}

